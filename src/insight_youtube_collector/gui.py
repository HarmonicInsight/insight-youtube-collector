"""
Streamlit GUI for Insight YouTube Collector.

Run with:
    streamlit run src/insight_youtube_collector/gui.py
    # or
    iyc-gui
"""

import streamlit as st
import os
import sys
from pathlib import Path
from datetime import datetime

# Add src to path for development
src_path = Path(__file__).parent.parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

from insight_youtube_collector import __version__
from insight_youtube_collector.collector import YouTubeCollector
from insight_youtube_collector.batch import BatchConfig, BatchCollector
from insight_youtube_collector.storage import WarehouseStorage
from insight_youtube_collector.config import Settings


def init_session_state():
    """Initialize session state variables."""
    if 'collection_results' not in st.session_state:
        st.session_state.collection_results = []
    if 'collection_log' not in st.session_state:
        st.session_state.collection_log = []
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'selected_videos' not in st.session_state:
        st.session_state.selected_videos = set()


def log_message(message: str):
    """Add message to collection log."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.collection_log.append(f"[{timestamp}] {message}")


def clear_log():
    """Clear collection log."""
    st.session_state.collection_log = []


def format_duration(seconds: int) -> str:
    """Format seconds as HH:MM:SS or MM:SS."""
    if not seconds:
        return "0:00"
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    return f"{m}:{s:02d}"


def search_videos(query: str, max_results: int):
    """Search for videos and store results in session state."""
    import time
    import io
    import contextlib
    log_message(f"æ¤œç´¢ä¸­: {query}")

    from insight_youtube_collector.extractor import VideoSourceExtractor
    import yt_dlp

    def fetch_video_info(vid: str, retry_count: int = 0) -> dict | None:
        """Fetch video info with retry on rate limit."""
        max_retries = 3
        url = f"https://www.youtube.com/watch?v={vid}"

        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'skip_download': True,
            'writesubtitles': False,
            'writeautomaticsub': False,
            'ignoreerrors': True,
            'no_color': True,
        }

        # Try with cookies first (only on first attempt)
        if retry_count == 0:
            ydl_opts['cookiesfrombrowser'] = ('chrome',)

        # Suppress stderr output from yt-dlp
        stderr_capture = io.StringIO()
        try:
            with contextlib.redirect_stderr(stderr_capture):
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url, download=False)
                    if info:
                        return info
        except Exception as e:
            error_msg = str(e).lower()
            # If cookie error, retry without cookies
            if 'cookie' in error_msg and 'cookiesfrombrowser' in ydl_opts:
                del ydl_opts['cookiesfrombrowser']
                try:
                    with contextlib.redirect_stderr(stderr_capture):
                        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                            info = ydl.extract_info(url, download=False)
                            if info:
                                return info
                except Exception:
                    pass
            # If rate limited, retry with backoff
            if '429' in str(e) and retry_count < max_retries:
                wait_time = (retry_count + 1) * 10  # 10, 20, 30 seconds
                log_message(f"  Rate limited, waiting {wait_time}s...")
                time.sleep(wait_time)
                return fetch_video_info(vid, retry_count + 1)

        return None

    try:
        with st.spinner("ğŸ” æ¤œç´¢ä¸­..."):
            source_extractor = VideoSourceExtractor(quiet=True)

            # Get video IDs from search
            video_ids = source_extractor.extract_from_search(query, max_results)

            if not video_ids:
                st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                log_message("æ¤œç´¢çµæœãªã—")
                return

            # Get metadata and subtitle info for each video
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, vid in enumerate(video_ids):
                status_text.text(f"å­—å¹•æƒ…å ±ã‚’ç¢ºèªä¸­... {i+1}/{len(video_ids)}")
                progress_bar.progress((i + 1) / len(video_ids))

                try:
                    info = fetch_video_info(vid)
                    if not info:
                        log_message(f"  ã‚¹ã‚­ãƒƒãƒ—: {vid} - æƒ…å ±å–å¾—å¤±æ•—")
                        continue

                    # Check if subtitles are available
                    subtitles = info.get('subtitles', {})
                    auto_captions = info.get('automatic_captions', {})
                    has_ja = 'ja' in subtitles or 'ja' in auto_captions
                    has_en = 'en' in subtitles or 'en' in auto_captions
                    has_any = bool(subtitles) or bool(auto_captions)

                    results.append({
                        'video_id': vid,
                        'title': info.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜)'),
                        'channel': info.get('channel', info.get('uploader', '')),
                        'duration': info.get('duration', 0),
                        'url': f"https://www.youtube.com/watch?v={vid}",
                        'has_subtitles': has_any,
                        'has_ja': has_ja,
                        'has_en': has_en,
                        'subtitle_langs': list(subtitles.keys()) + list(auto_captions.keys()),
                    })

                    # Add small delay between requests to avoid rate limiting
                    if i < len(video_ids) - 1:
                        time.sleep(1.5)

                except Exception as e:
                    log_message(f"  ã‚¹ã‚­ãƒƒãƒ—: {vid} - {e}")
                    continue

            progress_bar.empty()
            status_text.empty()

            # Filter to only videos with subtitles
            videos_with_subs = [r for r in results if r['has_subtitles']]

            st.session_state.search_results = videos_with_subs
            st.session_state.selected_videos = set()  # Clear previous selections

            total_found = len(results)
            with_subs = len(videos_with_subs)
            log_message(f"æ¤œç´¢å®Œäº†: {total_found} ä»¶ä¸­ {with_subs} ä»¶ãŒå­—å¹•ã‚ã‚Š")

            if videos_with_subs:
                st.success(f"âœ… {with_subs} ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆå­—å¹•ã‚ã‚Šï¼‰")
                if total_found > with_subs:
                    st.info(f"â„¹ï¸ å­—å¹•ãªã—ã® {total_found - with_subs} ä»¶ã¯é™¤å¤–ã•ã‚Œã¾ã—ãŸ")
            else:
                st.warning("å­—å¹•ã®ã‚ã‚‹å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            st.rerun()

    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")


def collect_selected_videos(video_ids: list, warehouse_dir: str, json_path: str):
    """Collect transcripts for selected videos."""
    clear_log()
    log_message(f"é¸æŠã—ãŸ {len(video_ids)} ä»¶ã®åé›†é–‹å§‹")

    settings = Settings(quiet_mode=True)
    collector = YouTubeCollector(settings)

    progress = st.progress(0)
    status = st.empty()

    try:
        videos = []
        total = len(video_ids)

        for i, vid in enumerate(video_ids):
            status.info(f"ğŸ”„ [{i+1}/{total}] ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—ä¸­...")
            log_message(f"å–å¾—ä¸­: {vid}")
            progress.progress((i + 1) / (total + 1))

            video_data = collector.collect_video(vid, verbose=False)
            if video_data:
                videos.append(video_data)
                if video_data.transcript and not video_data.transcript.error:
                    text_len = len(video_data.transcript.full_text)
                    seg_count = video_data.transcript.segment_count
                    log_message(f"  âœ“ {video_data.metadata.title} ({text_len}æ–‡å­—, {seg_count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ)")
                else:
                    error_msg = video_data.transcript.error if video_data.transcript else "ä¸æ˜"
                    log_message(f"  âœ— {video_data.metadata.title} - {error_msg}")

        log_message(f"å–å¾—å®Œäº†: {len(videos)} å‹•ç”»")

        if videos:
            # Save to warehouse
            if warehouse_dir:
                status.info("ğŸ’¾ Warehouseã«ä¿å­˜ä¸­...")
                log_message("Warehouseã«ä¿å­˜ä¸­...")
                result = collector.save_warehouse(videos, warehouse_dir=warehouse_dir)
                log_message(f"Warehouseä¿å­˜: {result['saved']} ãƒ•ã‚¡ã‚¤ãƒ«")

            # Save to JSON
            if json_path:
                log_message("JSONã«ä¿å­˜ä¸­...")
                collector.save_json(videos, output_path=json_path)
                log_message(f"JSONä¿å­˜: {json_path}")

            progress.progress(100)
            status.success(f"âœ… å®Œäº†: {len(videos)} å‹•ç”»ã‚’åé›†ã—ã¾ã—ãŸ")
            log_message("åé›†å®Œäº†!")

            # Clear search results
            st.session_state.search_results = []
            st.session_state.selected_videos = set()

            # Show results
            st.subheader("åé›†çµæœ")
            success_count = sum(1 for v in videos if v.transcript and not v.transcript.error)
            st.metric("ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—æˆåŠŸ", f"{success_count} / {len(videos)}")

            for v in videos[:10]:
                has_transcript = v.transcript and not v.transcript.error
                icon = "âœ“" if has_transcript else "âœ—"
                st.write(f"{icon} **{v.metadata.title}**")
            if len(videos) > 10:
                st.write(f"... ä»– {len(videos) - 10} ä»¶")
        else:
            status.warning("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            log_message("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """Main Streamlit app."""
    st.set_page_config(
        page_title="Insight YouTube Collector",
        page_icon="ğŸ¬",
        layout="wide",
    )

    init_session_state()

    # Header
    st.title("ğŸ¬ Insight YouTube Collector")
    st.caption(f"v{__version__} - Harmonic Insight Text Data Warehouse Tool")

    # Sidebar - Settings
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        warehouse_dir = st.text_input(
            "Warehouse ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
            value="data/warehouse/lectures",
            help="åé›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
        )

        max_videos = st.slider(
            "æœ€å¤§å‹•ç”»æ•°ï¼ˆã‚½ãƒ¼ã‚¹ã”ã¨ï¼‰",
            min_value=1,
            max_value=100,
            value=10,
            help="å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã™ã‚‹æœ€å¤§å‹•ç”»æ•°"
        )

        st.divider()

        # Output format
        st.subheader("å‡ºåŠ›å½¢å¼")
        save_warehouse = st.checkbox("Warehouseå½¢å¼ï¼ˆHMGç”¨ï¼‰", value=True)
        save_json = st.checkbox("JSONå½¢å¼", value=False)

        if save_json:
            json_path = st.text_input("JSONå‡ºåŠ›ãƒ‘ã‚¹", value="data/output/result.json")

        st.divider()

        # Warehouse status
        st.subheader("ğŸ“ Warehouse çŠ¶æ…‹")
        try:
            storage = WarehouseStorage(warehouse_dir=warehouse_dir)
            files = storage.list_files()
            st.metric("ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°", len(files))
        except Exception:
            st.info("WarehouseãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    # Main content - Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ” æ¤œç´¢ï¼†é¸æŠ",
        "ğŸ”— å˜ä¸€åé›†",
        "ğŸ“‹ ãƒãƒƒãƒåé›†",
        "ğŸ“ Warehouse",
        "ğŸ“œ ãƒ­ã‚°"
    ])

    # Tab 1: Search & Select
    with tab1:
        st.header("ğŸ” æ¤œç´¢ã—ã¦é¸æŠ")
        st.caption("æ¤œç´¢çµæœã‹ã‚‰å‹•ç”»ã‚’é¸ã‚“ã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—ã—ã¾ã™")

        # Search section
        col1, col2 = st.columns([3, 1])
        with col1:
            search_query = st.text_input(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                placeholder="å»ºè¨­DX AIæ´»ç”¨ ãªã©",
                key="search_query"
            )
        with col2:
            search_max = st.number_input("æ¤œç´¢ä»¶æ•°", min_value=5, max_value=50, value=20, key="search_max")

        if st.button("ğŸ” æ¤œç´¢", key="search_btn", type="primary"):
            if search_query:
                search_videos(search_query, search_max)
            else:
                st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # Display search results
        if st.session_state.search_results:
            st.divider()
            st.subheader(f"æ¤œç´¢çµæœ: {len(st.session_state.search_results)} ä»¶")

            # Select all / Deselect all buttons
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("âœ… ã™ã¹ã¦é¸æŠ"):
                    st.session_state.selected_videos = set(
                        v['video_id'] for v in st.session_state.search_results
                    )
                    st.rerun()
            with col2:
                if st.button("âŒ ã™ã¹ã¦è§£é™¤"):
                    st.session_state.selected_videos = set()
                    st.rerun()
            with col3:
                selected_count = len(st.session_state.selected_videos)
                st.write(f"é¸æŠä¸­: **{selected_count}** ä»¶")

            # Video list with checkboxes
            for v in st.session_state.search_results:
                vid = v['video_id']
                is_selected = vid in st.session_state.selected_videos

                col1, col2 = st.columns([0.05, 0.95])
                with col1:
                    if st.checkbox("é¸æŠ", value=is_selected, key=f"chk_{vid}", label_visibility="collapsed"):
                        st.session_state.selected_videos.add(vid)
                    else:
                        st.session_state.selected_videos.discard(vid)
                with col2:
                    duration = format_duration(v.get('duration', 0))
                    # Show subtitle language badges
                    lang_badges = []
                    if v.get('has_ja'):
                        lang_badges.append("ğŸ‡¯ğŸ‡µ")
                    if v.get('has_en'):
                        lang_badges.append("ğŸ‡ºğŸ‡¸")
                    lang_str = " ".join(lang_badges) if lang_badges else "ğŸ“"
                    st.markdown(f"**{v['title']}** {lang_str}  \n{v['channel']} â€¢ {duration}")

            st.divider()

            # Collect selected videos
            selected_count = len(st.session_state.selected_videos)
            if selected_count > 0:
                if st.button(f"ğŸš€ é¸æŠã—ãŸ {selected_count} ä»¶ã‚’åé›†", type="primary", use_container_width=True):
                    collect_selected_videos(
                        list(st.session_state.selected_videos),
                        warehouse_dir if save_warehouse else None,
                        json_path if save_json else None,
                    )
            else:
                st.info("åé›†ã™ã‚‹å‹•ç”»ã‚’é¸æŠã—ã¦ãã ã•ã„")

    # Tab 2: Single Collection
    with tab2:
        st.header("å˜ä¸€ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®åé›†")

        col1, col2 = st.columns([2, 1])

        with col1:
            source_type = st.selectbox(
                "ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—",
                ["å‹•ç”»URL", "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ", "ãƒãƒ£ãƒ³ãƒãƒ«", "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
                key="single_source_type"
            )

            if source_type == "å‹•ç”»URL":
                source_value = st.text_area(
                    "YouTube URLï¼ˆè¤‡æ•°ã®å ´åˆã¯1è¡Œ1URLï¼‰",
                    height=100,
                    placeholder="https://www.youtube.com/watch?v=...",
                    key="single_urls"
                )
            elif source_type == "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ":
                source_value = st.text_input(
                    "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ URL",
                    placeholder="https://www.youtube.com/playlist?list=...",
                    key="single_playlist"
                )
            elif source_type == "ãƒãƒ£ãƒ³ãƒãƒ«":
                source_value = st.text_input(
                    "ãƒãƒ£ãƒ³ãƒãƒ« URL",
                    placeholder="https://www.youtube.com/@channelname",
                    key="single_channel"
                )
            else:
                source_value = st.text_input(
                    "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                    placeholder="å»ºè¨­DX AIæ´»ç”¨",
                    key="single_search"
                )

        with col2:
            st.write("")  # Spacer
            st.write("")
            if st.button("ğŸš€ åé›†é–‹å§‹", key="single_collect", type="primary", use_container_width=True):
                if source_value:
                    collect_single(
                        source_type,
                        source_value,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                        json_path if save_json else None,
                    )
                else:
                    st.warning("ã‚½ãƒ¼ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # Tab 3: Batch Collection
    with tab3:
        st.header("ãƒãƒƒãƒåé›†")

        batch_mode = st.radio(
            "å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰",
            ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ", "URLãƒªã‚¹ãƒˆ", "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"],
            horizontal=True
        )

        if batch_mode == "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ":
            keywords_text = st.text_area(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ1è¡Œ1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰",
                height=200,
                placeholder="å»ºè¨­DX AIæ´»ç”¨\næ–½å·¥ç®¡ç† ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–\nBIM æ´»ç”¨äº‹ä¾‹",
                key="batch_keywords"
            )

            if st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_keywords_btn", type="primary"):
                if keywords_text.strip():
                    keywords = [k.strip() for k in keywords_text.strip().split('\n') if k.strip()]
                    collect_batch_keywords(
                        keywords,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                    )
                else:
                    st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        elif batch_mode == "URLãƒªã‚¹ãƒˆ":
            urls_text = st.text_area(
                "URLï¼ˆ1è¡Œ1URLã€ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ/ãƒãƒ£ãƒ³ãƒãƒ«/å‹•ç”»ã‚’æ··åœ¨å¯ï¼‰",
                height=200,
                placeholder="https://www.youtube.com/playlist?list=...\nhttps://www.youtube.com/@channelname\nhttps://www.youtube.com/watch?v=...",
                key="batch_urls"
            )

            if st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_urls_btn", type="primary"):
                if urls_text.strip():
                    urls = [u.strip() for u in urls_text.strip().split('\n') if u.strip()]
                    collect_batch_urls(
                        urls,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                    )
                else:
                    st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        else:  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            config_file = st.file_uploader(
                "YAML/JSON è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
                type=['yaml', 'yml', 'json'],
                key="batch_config_file"
            )

            if config_file and st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_config_btn", type="primary"):
                collect_batch_config(config_file, warehouse_dir)

    # Tab 4: Warehouse Browser
    with tab4:
        st.header("Warehouse ãƒ–ãƒ©ã‚¦ã‚¶")

        try:
            storage = WarehouseStorage(warehouse_dir=warehouse_dir)
            files = storage.list_files()
            manifest = storage.get_manifest()

            if files:
                st.success(f"ğŸ“ {len(files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

                # File list with search
                search = st.text_input("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¤œç´¢", key="warehouse_search")

                filtered_files = files
                if search:
                    filtered_files = [f for f in files if search.lower() in f.lower()]

                for f in filtered_files[:50]:  # Limit display
                    meta = manifest.get("files", {}).get(f, {})
                    title = meta.get("source_title", "")
                    channel = meta.get("channel", "")

                    with st.expander(f"ğŸ“„ {f[:60]}..."):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {title}")
                            st.write(f"**ãƒãƒ£ãƒ³ãƒãƒ«:** {channel}")
                        with col2:
                            st.write(f"**åé›†æ—¥:** {meta.get('observed_at', 'N/A')}")
                            st.write(f"**å…¬é–‹æ—¥:** {meta.get('upload_date', 'N/A')}")

                        # Read and display file content preview
                        file_path = Path(warehouse_dir) / f
                        if file_path.exists():
                            content = file_path.read_text(encoding='utf-8')
                            file_size = file_path.stat().st_size
                            st.caption(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes / {len(content):,} æ–‡å­—")
                            if len(content) > 2000:
                                st.text_area("å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (æœ€åˆã®2000æ–‡å­—)", content[:2000] + "\n\n... (ä»¥ä¸‹çœç•¥)", height=200, disabled=True)
                            else:
                                st.text_area("å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", content, height=200, disabled=True)

                if len(filtered_files) > 50:
                    st.info(f"... ä»– {len(filtered_files) - 50} ãƒ•ã‚¡ã‚¤ãƒ«")

            else:
                st.info("Warehouseã¯ç©ºã§ã™ã€‚åé›†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"Warehouseèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # Tab 5: Log
    with tab5:
        st.header("åé›†ãƒ­ã‚°")

        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("ğŸ—‘ï¸ ãƒ­ã‚°ã‚¯ãƒªã‚¢"):
                clear_log()
                st.rerun()

        if st.session_state.collection_log:
            log_text = "\n".join(st.session_state.collection_log)
            st.code(log_text, language=None)
        else:
            st.info("ãƒ­ã‚°ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“")


def collect_single(source_type, source_value, max_videos, warehouse_dir, json_path):
    """Collect from a single source."""
    clear_log()
    log_message(f"åé›†é–‹å§‹: {source_type}")

    settings = Settings(quiet_mode=True)
    collector = YouTubeCollector(settings)

    progress = st.progress(0)
    status = st.empty()

    try:
        status.info("ğŸ”„ å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")
        log_message("å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")

        videos = []
        if source_type == "å‹•ç”»URL":
            urls = [u.strip() for u in source_value.strip().split('\n') if u.strip()]
            videos = collector.collect_from_urls(urls, max_videos=max_videos, verbose=False)
        elif source_type == "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ":
            videos = collector.collect_from_playlist(source_value, max_videos=max_videos, verbose=False)
        elif source_type == "ãƒãƒ£ãƒ³ãƒãƒ«":
            videos = collector.collect_from_channel(source_value, max_videos=max_videos, verbose=False)
        else:
            videos = collector.collect_from_search(source_value, max_videos=max_videos, verbose=False)

        progress.progress(50)
        log_message(f"å–å¾—å®Œäº†: {len(videos)} å‹•ç”»")

        if videos:
            # Save to warehouse
            if warehouse_dir:
                status.info("ğŸ’¾ Warehouseã«ä¿å­˜ä¸­...")
                log_message("Warehouseã«ä¿å­˜ä¸­...")
                result = collector.save_warehouse(videos, warehouse_dir=warehouse_dir)
                log_message(f"Warehouseä¿å­˜: {result['saved']} ãƒ•ã‚¡ã‚¤ãƒ«")

            # Save to JSON
            if json_path:
                log_message("JSONã«ä¿å­˜ä¸­...")
                collector.save_json(videos, output_path=json_path)
                log_message(f"JSONä¿å­˜: {json_path}")

            progress.progress(100)
            status.success(f"âœ… å®Œäº†: {len(videos)} å‹•ç”»ã‚’åé›†ã—ã¾ã—ãŸ")
            log_message("åé›†å®Œäº†!")

            # Show results
            st.subheader("åé›†çµæœ")
            for v in videos[:10]:
                st.write(f"- **{v.metadata.title}** ({v.metadata.channel})")
            if len(videos) > 10:
                st.write(f"... ä»– {len(videos) - 10} ä»¶")

        else:
            status.warning("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            log_message("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_keywords(keywords, max_videos, warehouse_dir):
    """Batch collect from keywords."""
    clear_log()
    log_message(f"ãƒãƒƒãƒåé›†é–‹å§‹: {len(keywords)} ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")

    from insight_youtube_collector.batch import BatchConfig, SourceConfig, BatchCollector

    # Build config
    sources = [SourceConfig("keyword", kw, max_videos) for kw in keywords]
    config = BatchConfig(
        sources=sources,
        save_warehouse=bool(warehouse_dir),
        warehouse_dir=warehouse_dir or "data/warehouse/lectures",
        save_json=False,
    )

    progress = st.progress(0)
    status = st.empty()

    try:
        total = len(keywords)
        for i, kw in enumerate(keywords):
            status.info(f"ğŸ”„ [{i+1}/{total}] æ¤œç´¢ä¸­: {kw}")
            log_message(f"æ¤œç´¢ä¸­: {kw}")
            progress.progress((i + 1) / (total + 1))

        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        # Show summary
        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])
        if result.get('save_results', {}).get('warehouse'):
            wh = result['save_results']['warehouse']
            st.metric("ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«æ•°", wh['saved'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_urls(urls, max_videos, warehouse_dir):
    """Batch collect from URLs."""
    clear_log()
    log_message(f"ãƒãƒƒãƒåé›†é–‹å§‹: {len(urls)} URL")

    from insight_youtube_collector.batch import BatchConfig, SourceConfig, BatchCollector

    # Auto-detect source types
    sources = []
    for url in urls:
        if 'playlist?list=' in url:
            sources.append(SourceConfig("playlist", url, max_videos))
        elif '/@' in url or '/channel/' in url or '/c/' in url:
            sources.append(SourceConfig("channel", url, max_videos))
        else:
            sources.append(SourceConfig("url", url, 1))

    config = BatchConfig(
        sources=sources,
        save_warehouse=bool(warehouse_dir),
        warehouse_dir=warehouse_dir or "data/warehouse/lectures",
        save_json=False,
    )

    progress = st.progress(0)
    status = st.empty()

    try:
        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_config(config_file, warehouse_dir):
    """Batch collect from config file."""
    import tempfile
    import yaml
    import json

    clear_log()
    log_message("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒƒãƒåé›†é–‹å§‹")

    progress = st.progress(0)
    status = st.empty()

    try:
        # Save uploaded file temporarily
        content = config_file.read().decode('utf-8')

        if config_file.name.endswith('.json'):
            data = json.loads(content)
        else:
            import yaml
            data = yaml.safe_load(content)

        config = BatchConfig.from_dict(data)
        log_message(f"è¨­å®šèª­ã¿è¾¼ã¿: {len(config.sources)} ã‚½ãƒ¼ã‚¹")

        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    main()
