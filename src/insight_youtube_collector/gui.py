"""
Streamlit GUI for Insight YouTube Collector.

Run with:
    streamlit run src/insight_youtube_collector/gui.py
    # or
    iyc-gui
"""

import streamlit as st
import os
import sys
from pathlib import Path
from datetime import datetime

# Add src to path for development
src_path = Path(__file__).parent.parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

from insight_youtube_collector import __version__
from insight_youtube_collector.collector import YouTubeCollector
from insight_youtube_collector.batch import BatchConfig, BatchCollector
from insight_youtube_collector.storage import WarehouseStorage
from insight_youtube_collector.config import Settings


def init_session_state():
    """Initialize session state variables."""
    if 'collection_results' not in st.session_state:
        st.session_state.collection_results = []
    if 'collection_log' not in st.session_state:
        st.session_state.collection_log = []
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'selected_videos' not in st.session_state:
        st.session_state.selected_videos = set()


def log_message(message: str):
    """Add message to collection log."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.collection_log.append(f"[{timestamp}] {message}")


def clear_log():
    """Clear collection log."""
    st.session_state.collection_log = []


def format_duration(seconds: int) -> str:
    """Format seconds as HH:MM:SS or MM:SS."""
    if not seconds:
        return "0:00"
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    return f"{m}:{s:02d}"


class NullLogger:
    """Null logger to suppress all yt-dlp output."""
    def debug(self, msg): pass
    def info(self, msg): pass
    def warning(self, msg): pass
    def error(self, msg): pass


def search_videos(query: str, max_results: int):
    """Search for videos and store results in session state."""
    import time
    import os
    import sys
    log_message(f"æ¤œç´¢ä¸­: {query}")

    from insight_youtube_collector.extractor import VideoSourceExtractor
    import yt_dlp

    def fetch_video_info(vid: str, retry_count: int = 0) -> dict | None:
        """Fetch video info with retry on rate limit."""
        max_retries = 3
        url = f"https://www.youtube.com/watch?v={vid}"

        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'skip_download': True,
            'writesubtitles': False,
            'writeautomaticsub': False,
            'ignoreerrors': True,
            'no_color': True,
            'logger': NullLogger(),
        }

        # Try with cookies first (only on first attempt)
        if retry_count == 0:
            ydl_opts['cookiesfrombrowser'] = ('chrome',)

        # Suppress stderr completely by redirecting to devnull
        old_stderr = sys.stderr
        try:
            sys.stderr = open(os.devnull, 'w')
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                if info:
                    return info
        except Exception as e:
            error_msg = str(e).lower()
            # If cookie error, retry without cookies
            if 'cookie' in error_msg and 'cookiesfrombrowser' in ydl_opts:
                del ydl_opts['cookiesfrombrowser']
                try:
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(url, download=False)
                        if info:
                            return info
                except Exception:
                    pass
            # If rate limited, retry with backoff
            if '429' in str(e) and retry_count < max_retries:
                wait_time = (retry_count + 1) * 10  # 10, 20, 30 seconds
                log_message(f"  Rate limited, waiting {wait_time}s...")
                time.sleep(wait_time)
                return fetch_video_info(vid, retry_count + 1)
        finally:
            sys.stderr.close()
            sys.stderr = old_stderr

        return None

    try:
        with st.spinner("ğŸ” æ¤œç´¢ä¸­..."):
            source_extractor = VideoSourceExtractor(quiet=True)

            # Get video IDs from search
            video_ids = source_extractor.extract_from_search(query, max_results)

            if not video_ids:
                st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                log_message("æ¤œç´¢çµæœãªã—")
                return

            # Get metadata and subtitle info for each video
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, vid in enumerate(video_ids):
                status_text.text(f"å­—å¹•æƒ…å ±ã‚’ç¢ºèªä¸­... {i+1}/{len(video_ids)}")
                progress_bar.progress((i + 1) / len(video_ids))

                try:
                    info = fetch_video_info(vid)
                    if not info:
                        log_message(f"  ã‚¹ã‚­ãƒƒãƒ—: {vid} - æƒ…å ±å–å¾—å¤±æ•—")
                        continue

                    # Check if subtitles are available
                    subtitles = info.get('subtitles', {})
                    auto_captions = info.get('automatic_captions', {})
                    has_ja = 'ja' in subtitles or 'ja' in auto_captions
                    has_en = 'en' in subtitles or 'en' in auto_captions
                    has_any = bool(subtitles) or bool(auto_captions)

                    results.append({
                        'video_id': vid,
                        'title': info.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜)'),
                        'channel': info.get('channel', info.get('uploader', '')),
                        'duration': info.get('duration', 0),
                        'url': f"https://www.youtube.com/watch?v={vid}",
                        'has_subtitles': has_any,
                        'has_ja': has_ja,
                        'has_en': has_en,
                        'subtitle_langs': list(subtitles.keys()) + list(auto_captions.keys()),
                    })

                    # Add small delay between requests to avoid rate limiting
                    if i < len(video_ids) - 1:
                        time.sleep(1.5)

                except Exception as e:
                    log_message(f"  ã‚¹ã‚­ãƒƒãƒ—: {vid} - {e}")
                    continue

            progress_bar.empty()
            status_text.empty()

            # Filter to only videos with subtitles
            videos_with_subs = [r for r in results if r['has_subtitles']]

            st.session_state.search_results = videos_with_subs
            st.session_state.selected_videos = set()  # Clear previous selections

            total_found = len(results)
            with_subs = len(videos_with_subs)
            log_message(f"æ¤œç´¢å®Œäº†: {total_found} ä»¶ä¸­ {with_subs} ä»¶ãŒå­—å¹•ã‚ã‚Š")

            if videos_with_subs:
                st.success(f"âœ… {with_subs} ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆå­—å¹•ã‚ã‚Šï¼‰")
                if total_found > with_subs:
                    st.info(f"â„¹ï¸ å­—å¹•ãªã—ã® {total_found - with_subs} ä»¶ã¯é™¤å¤–ã•ã‚Œã¾ã—ãŸ")
            else:
                st.warning("å­—å¹•ã®ã‚ã‚‹å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            st.rerun()

    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")


def collect_selected_videos(video_ids: list, warehouse_dir: str, json_path: str):
    """Collect transcripts for selected videos."""
    clear_log()
    log_message(f"é¸æŠã—ãŸ {len(video_ids)} ä»¶ã®åé›†é–‹å§‹")

    settings = Settings(quiet_mode=True)
    collector = YouTubeCollector(settings, status_callback=log_message)

    progress = st.progress(0)
    status = st.empty()

    try:
        videos = []
        total = len(video_ids)

        for i, vid in enumerate(video_ids):
            status.info(f"ğŸ”„ [{i+1}/{total}] ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—ä¸­...")
            log_message(f"å–å¾—ä¸­: {vid}")
            progress.progress((i + 1) / (total + 1))

            video_data = collector.collect_video(vid, verbose=False)
            if video_data:
                videos.append(video_data)
                if video_data.transcript and not video_data.transcript.error:
                    text_len = len(video_data.transcript.full_text)
                    seg_count = video_data.transcript.segment_count
                    log_message(f"  âœ“ {video_data.metadata.title} ({text_len}æ–‡å­—, {seg_count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ)")
                else:
                    error_msg = video_data.transcript.error if video_data.transcript else "ä¸æ˜"
                    log_message(f"  âœ— {video_data.metadata.title} - {error_msg}")

        log_message(f"å–å¾—å®Œäº†: {len(videos)} å‹•ç”»")

        if videos:
            # Save to warehouse
            if warehouse_dir:
                status.info("ğŸ’¾ Warehouseã«ä¿å­˜ä¸­...")
                log_message("Warehouseã«ä¿å­˜ä¸­...")
                result = collector.save_warehouse(videos, warehouse_dir=warehouse_dir)
                saved = result['saved']
                skipped = result.get('skipped', 0)
                if skipped > 0:
                    log_message(f"Warehouseä¿å­˜: {saved} ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{skipped} ä»¶ã¯æ—¢å­˜ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                else:
                    log_message(f"Warehouseä¿å­˜: {saved} ãƒ•ã‚¡ã‚¤ãƒ«")

            # Save to JSON
            if json_path:
                log_message("JSONã«ä¿å­˜ä¸­...")
                collector.save_json(videos, output_path=json_path)
                log_message(f"JSONä¿å­˜: {json_path}")

            progress.progress(100)
            status.success(f"âœ… å®Œäº†: {len(videos)} å‹•ç”»ã‚’åé›†ã—ã¾ã—ãŸ")
            log_message("åé›†å®Œäº†!")

            # Clear search results
            st.session_state.search_results = []
            st.session_state.selected_videos = set()

            # Show results
            st.subheader("åé›†çµæœ")
            success_count = sum(1 for v in videos if v.transcript and not v.transcript.error)
            st.metric("ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—æˆåŠŸ", f"{success_count} / {len(videos)}")

            for v in videos[:10]:
                has_transcript = v.transcript and not v.transcript.error
                icon = "âœ“" if has_transcript else "âœ—"
                st.write(f"{icon} **{v.metadata.title}**")
            if len(videos) > 10:
                st.write(f"... ä»– {len(videos) - 10} ä»¶")
        else:
            status.warning("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            log_message("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def generate_mart(selected_files: list, mart_type: str, warehouse_dir: str, output_dir: str):
    """Generate a knowledge mart from selected warehouse files."""
    clear_log()
    log_message(f"ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹: {mart_type}")
    log_message(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(selected_files)}")

    progress = st.progress(0)
    status = st.empty()

    try:
        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Read all selected files
        status.info("ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        all_content = []
        warehouse_path = Path(warehouse_dir)

        for i, filename in enumerate(selected_files):
            file_path = warehouse_path / filename
            if file_path.exists():
                content = file_path.read_text(encoding='utf-8')
                all_content.append({
                    'filename': filename,
                    'content': content,
                    'length': len(content)
                })
                log_message(f"  èª­ã¿è¾¼ã¿: {filename} ({len(content)}æ–‡å­—)")
            progress.progress((i + 1) / (len(selected_files) + 2))

        if not all_content:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
            return

        # Generate mart based on type
        status.info(f"ğŸ§  {mart_type}ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        log_message(f"ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {mart_type}")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"{mart_type}_mart_{timestamp}.md"
        output_file = output_path / output_filename

        # Generate mart content based on type
        mart_content = _generate_mart_content(mart_type, all_content)

        # Write output file
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(mart_content)

        progress.progress(100)
        status.success(f"âœ… ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†!")
        log_message(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        log_message(f"ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†!")

        # Show result
        st.subheader("ğŸ“„ ç”Ÿæˆçµæœ")
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«: `{output_file}`")
        st.metric("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°", len(all_content))
        st.metric("ç·æ–‡å­—æ•°", sum(c['length'] for c in all_content))

        # Preview
        with st.expander("ğŸ“ ãƒãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (æœ€åˆã®3000æ–‡å­—)"):
            st.markdown(mart_content[:3000] + ("\n\n..." if len(mart_content) > 3000 else ""))

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def _generate_mart_content(mart_type: str, content_list: list) -> str:
    """Generate mart content based on type."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    header = f"""# {mart_type.upper()} ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {timestamp}
**å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(content_list)}
**ç·æ–‡å­—æ•°**: {sum(c['length'] for c in content_list):,}

---

"""

    if mart_type == "term":
        header += """## ç”¨èªå®šç¾©ãƒãƒ¼ãƒˆ

ã“ã®ãƒãƒ¼ãƒˆã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå°‚é–€ç”¨èªã¨å®šç¾©ã‚’å«ã¿ã¾ã™ã€‚

### æŠ½å‡ºå¯¾è±¡
- å°‚é–€ç”¨èªã¨èª¬æ˜
- ç•¥èªã¨ãã®æ­£å¼åç§°
- æ¦‚å¿µã®å®šç¾©

---

"""
    elif mart_type == "regulation":
        header += """## æ³•ä»¤ãƒ»åŸºæº–ãƒãƒ¼ãƒˆ

ã“ã®ãƒãƒ¼ãƒˆã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸæ³•ä»¤ãƒ»åŸºæº–æƒ…å ±ã‚’å«ã¿ã¾ã™ã€‚

### æŠ½å‡ºå¯¾è±¡
- æ³•å¾‹ãƒ»æ¡ä¾‹ã®è¨€åŠ
- æ¥­ç•ŒåŸºæº–ãƒ»è¦æ ¼
- ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶

---

"""
    elif mart_type == "process":
        header += """## ä½œæ¥­æ‰‹é †ãƒãƒ¼ãƒˆ

ã“ã®ãƒãƒ¼ãƒˆã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸæ‰‹é †ãƒ»ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å«ã¿ã¾ã™ã€‚

### æŠ½å‡ºå¯¾è±¡
- ä½œæ¥­æ‰‹é †ãƒ»ã‚¹ãƒ†ãƒƒãƒ—
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

---

"""

    # Add source content sections
    content_sections = []
    for item in content_list:
        section = f"""
## ã‚½ãƒ¼ã‚¹: {item['filename']}

{item['content'][:5000]}{"..." if len(item['content']) > 5000 else ""}

---
"""
        content_sections.append(section)

    return header + "\n".join(content_sections)


def main():
    """Main Streamlit app."""
    st.set_page_config(
        page_title="Insight YouTube Collector",
        page_icon="ğŸ¬",
        layout="wide",
    )

    init_session_state()

    # Header
    st.title("ğŸ¬ Insight YouTube Collector")
    st.caption(f"v{__version__} - Harmonic Insight Text Data Warehouse Tool")

    # Sidebar - Settings
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        warehouse_dir = st.text_input(
            "Warehouse ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
            value="data/warehouse/lectures",
            help="åé›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
        )

        max_videos = st.slider(
            "æœ€å¤§å‹•ç”»æ•°ï¼ˆã‚½ãƒ¼ã‚¹ã”ã¨ï¼‰",
            min_value=1,
            max_value=100,
            value=10,
            help="å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã™ã‚‹æœ€å¤§å‹•ç”»æ•°"
        )

        st.divider()

        # Output format
        st.subheader("å‡ºåŠ›å½¢å¼")
        save_warehouse = st.checkbox("Warehouseå½¢å¼ï¼ˆHMGç”¨ï¼‰", value=True)
        save_json = st.checkbox("JSONå½¢å¼", value=False)

        if save_json:
            json_path = st.text_input("JSONå‡ºåŠ›ãƒ‘ã‚¹", value="data/output/result.json")

        st.divider()

        # Warehouse status
        st.subheader("ğŸ“ Warehouse çŠ¶æ…‹")
        try:
            storage = WarehouseStorage(warehouse_dir=warehouse_dir)
            files = storage.list_files()
            st.metric("ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°", len(files))
        except Exception:
            st.info("WarehouseãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    # Main content - Tabs
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ” æ¤œç´¢ï¼†é¸æŠ",
        "ğŸ”— å˜ä¸€åé›†",
        "ğŸ“‹ ãƒãƒƒãƒåé›†",
        "ğŸ“ Warehouse",
        "ğŸ§  ãƒãƒ¼ãƒˆç”Ÿæˆ",
        "ğŸ“œ ãƒ­ã‚°"
    ])

    # Tab 1: Search & Select
    with tab1:
        st.header("ğŸ” æ¤œç´¢ã—ã¦é¸æŠ")
        st.caption("æ¤œç´¢çµæœã‹ã‚‰å‹•ç”»ã‚’é¸ã‚“ã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—ã—ã¾ã™")

        # Search section
        col1, col2 = st.columns([3, 1])
        with col1:
            search_query = st.text_input(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                placeholder="å»ºè¨­DX AIæ´»ç”¨ ãªã©",
                key="search_query"
            )
        with col2:
            search_max = st.number_input("æ¤œç´¢ä»¶æ•°", min_value=5, max_value=50, value=20, key="search_max")

        if st.button("ğŸ” æ¤œç´¢", key="search_btn", type="primary"):
            if search_query:
                search_videos(search_query, search_max)
            else:
                st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # Display search results
        if st.session_state.search_results:
            st.divider()
            st.subheader(f"æ¤œç´¢çµæœ: {len(st.session_state.search_results)} ä»¶")

            # Select all / Deselect all buttons
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("âœ… ã™ã¹ã¦é¸æŠ"):
                    for v in st.session_state.search_results:
                        vid = v['video_id']
                        st.session_state.selected_videos.add(vid)
                        st.session_state[f"chk_{vid}"] = True
                    st.rerun()
            with col2:
                if st.button("âŒ ã™ã¹ã¦è§£é™¤"):
                    for v in st.session_state.search_results:
                        vid = v['video_id']
                        st.session_state.selected_videos.discard(vid)
                        st.session_state[f"chk_{vid}"] = False
                    st.rerun()
            with col3:
                selected_count = len(st.session_state.selected_videos)
                st.write(f"é¸æŠä¸­: **{selected_count}** ä»¶")

            # Video list with checkboxes
            for v in st.session_state.search_results:
                vid = v['video_id']
                is_selected = vid in st.session_state.selected_videos

                col1, col2 = st.columns([0.05, 0.95])
                with col1:
                    if st.checkbox("é¸æŠ", value=is_selected, key=f"chk_{vid}", label_visibility="collapsed"):
                        st.session_state.selected_videos.add(vid)
                    else:
                        st.session_state.selected_videos.discard(vid)
                with col2:
                    duration = format_duration(v.get('duration', 0))
                    # Show subtitle language badges
                    lang_badges = []
                    if v.get('has_ja'):
                        lang_badges.append("ğŸ‡¯ğŸ‡µ")
                    if v.get('has_en'):
                        lang_badges.append("ğŸ‡ºğŸ‡¸")
                    lang_str = " ".join(lang_badges) if lang_badges else "ğŸ“"
                    st.markdown(f"**{v['title']}** {lang_str}  \n{v['channel']} â€¢ {duration}")

            st.divider()

            # Collect selected videos
            selected_count = len(st.session_state.selected_videos)
            if selected_count > 0:
                if st.button(f"ğŸš€ é¸æŠã—ãŸ {selected_count} ä»¶ã‚’åé›†", type="primary", use_container_width=True):
                    collect_selected_videos(
                        list(st.session_state.selected_videos),
                        warehouse_dir if save_warehouse else None,
                        json_path if save_json else None,
                    )
            else:
                st.info("åé›†ã™ã‚‹å‹•ç”»ã‚’é¸æŠã—ã¦ãã ã•ã„")

    # Tab 2: Single Collection
    with tab2:
        st.header("å˜ä¸€ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®åé›†")

        col1, col2 = st.columns([2, 1])

        with col1:
            source_type = st.selectbox(
                "ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—",
                ["å‹•ç”»URL", "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ", "ãƒãƒ£ãƒ³ãƒãƒ«", "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
                key="single_source_type"
            )

            if source_type == "å‹•ç”»URL":
                source_value = st.text_area(
                    "YouTube URLï¼ˆè¤‡æ•°ã®å ´åˆã¯1è¡Œ1URLï¼‰",
                    height=100,
                    placeholder="https://www.youtube.com/watch?v=...",
                    key="single_urls"
                )
            elif source_type == "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ":
                source_value = st.text_input(
                    "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ URL",
                    placeholder="https://www.youtube.com/playlist?list=...",
                    key="single_playlist"
                )
            elif source_type == "ãƒãƒ£ãƒ³ãƒãƒ«":
                source_value = st.text_input(
                    "ãƒãƒ£ãƒ³ãƒãƒ« URL",
                    placeholder="https://www.youtube.com/@channelname",
                    key="single_channel"
                )
            else:
                source_value = st.text_input(
                    "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                    placeholder="å»ºè¨­DX AIæ´»ç”¨",
                    key="single_search"
                )

        with col2:
            st.write("")  # Spacer
            st.write("")
            if st.button("ğŸš€ åé›†é–‹å§‹", key="single_collect", type="primary", use_container_width=True):
                if source_value:
                    collect_single(
                        source_type,
                        source_value,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                        json_path if save_json else None,
                    )
                else:
                    st.warning("ã‚½ãƒ¼ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # Tab 3: Batch Collection
    with tab3:
        st.header("ãƒãƒƒãƒåé›†")

        batch_mode = st.radio(
            "å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰",
            ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ", "URLãƒªã‚¹ãƒˆ", "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"],
            horizontal=True
        )

        if batch_mode == "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ":
            keywords_text = st.text_area(
                "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ1è¡Œ1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰",
                height=200,
                placeholder="å»ºè¨­DX AIæ´»ç”¨\næ–½å·¥ç®¡ç† ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–\nBIM æ´»ç”¨äº‹ä¾‹",
                key="batch_keywords"
            )

            if st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_keywords_btn", type="primary"):
                if keywords_text.strip():
                    keywords = [k.strip() for k in keywords_text.strip().split('\n') if k.strip()]
                    collect_batch_keywords(
                        keywords,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                    )
                else:
                    st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        elif batch_mode == "URLãƒªã‚¹ãƒˆ":
            urls_text = st.text_area(
                "URLï¼ˆ1è¡Œ1URLã€ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ/ãƒãƒ£ãƒ³ãƒãƒ«/å‹•ç”»ã‚’æ··åœ¨å¯ï¼‰",
                height=200,
                placeholder="https://www.youtube.com/playlist?list=...\nhttps://www.youtube.com/@channelname\nhttps://www.youtube.com/watch?v=...",
                key="batch_urls"
            )

            if st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_urls_btn", type="primary"):
                if urls_text.strip():
                    urls = [u.strip() for u in urls_text.strip().split('\n') if u.strip()]
                    collect_batch_urls(
                        urls,
                        max_videos,
                        warehouse_dir if save_warehouse else None,
                    )
                else:
                    st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        else:  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            config_file = st.file_uploader(
                "YAML/JSON è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
                type=['yaml', 'yml', 'json'],
                key="batch_config_file"
            )

            if config_file and st.button("ğŸš€ ãƒãƒƒãƒåé›†é–‹å§‹", key="batch_config_btn", type="primary"):
                collect_batch_config(config_file, warehouse_dir)

    # Tab 4: Warehouse Browser
    with tab4:
        st.header("Warehouse ãƒ–ãƒ©ã‚¦ã‚¶")

        try:
            storage = WarehouseStorage(warehouse_dir=warehouse_dir)
            files = storage.list_files()
            manifest = storage.get_manifest()

            if files:
                st.success(f"ğŸ“ {len(files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

                # File list with search
                search = st.text_input("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¤œç´¢", key="warehouse_search")

                filtered_files = files
                if search:
                    filtered_files = [f for f in files if search.lower() in f.lower()]

                for f in filtered_files[:50]:  # Limit display
                    meta = manifest.get("files", {}).get(f, {})
                    title = meta.get("source_title", "")
                    channel = meta.get("channel", "")

                    with st.expander(f"ğŸ“„ {f[:60]}..."):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {title}")
                            st.write(f"**ãƒãƒ£ãƒ³ãƒãƒ«:** {channel}")
                        with col2:
                            st.write(f"**åé›†æ—¥:** {meta.get('observed_at', 'N/A')}")
                            st.write(f"**å…¬é–‹æ—¥:** {meta.get('upload_date', 'N/A')}")

                        # Read and display file content preview
                        file_path = Path(warehouse_dir) / f
                        if file_path.exists():
                            content = file_path.read_text(encoding='utf-8')
                            file_size = file_path.stat().st_size
                            st.caption(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes / {len(content):,} æ–‡å­—")
                            if len(content) > 2000:
                                st.text_area("å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (æœ€åˆã®2000æ–‡å­—)", content[:2000] + "\n\n... (ä»¥ä¸‹çœç•¥)", height=200, disabled=True)
                            else:
                                st.text_area("å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", content, height=200, disabled=True)

                if len(filtered_files) > 50:
                    st.info(f"... ä»– {len(filtered_files) - 50} ãƒ•ã‚¡ã‚¤ãƒ«")

            else:
                st.info("Warehouseã¯ç©ºã§ã™ã€‚åé›†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"Warehouseèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # Tab 5: Mart Generation
    with tab5:
        st.header("ğŸ§  ãƒãƒ¼ãƒˆç”Ÿæˆ")
        st.caption("Warehouseã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åˆ†æã—ã¦ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™")

        try:
            storage = WarehouseStorage(warehouse_dir=warehouse_dir)
            files = storage.list_files()
            manifest = storage.get_manifest()

            if not files:
                st.warning("Warehouseã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åé›†ã—ã¦ãã ã•ã„ã€‚")
            else:
                # Mart type selection
                st.subheader("ğŸ“‹ ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—é¸æŠ")
                mart_type = st.selectbox(
                    "ç”Ÿæˆã™ã‚‹ãƒãƒ¼ãƒˆã®ç¨®é¡",
                    options=["term", "regulation", "process"],
                    format_func=lambda x: {
                        "term": "ğŸ“š ç”¨èªå®šç¾© (term) - å°‚é–€ç”¨èªã¨å®šç¾©ã‚’æŠ½å‡º",
                        "regulation": "ğŸ“œ æ³•ä»¤ãƒ»åŸºæº– (regulation) - æ³•è¦åˆ¶ãƒ»åŸºæº–æƒ…å ±ã‚’æŠ½å‡º",
                        "process": "ğŸ”„ ä½œæ¥­æ‰‹é † (process) - æ‰‹é †ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ã‚’æŠ½å‡º"
                    }.get(x, x),
                    key="mart_type"
                )

                st.divider()

                # File selection
                st.subheader("ğŸ“ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ")

                # Initialize mart_selected_files in session state
                if 'mart_selected_files' not in st.session_state:
                    st.session_state.mart_selected_files = set()

                col1, col2, col3 = st.columns([1, 1, 2])
                with col1:
                    if st.button("âœ… ã™ã¹ã¦é¸æŠ", key="mart_select_all"):
                        st.session_state.mart_selected_files = set(files)
                        st.rerun()
                with col2:
                    if st.button("âŒ ã™ã¹ã¦è§£é™¤", key="mart_deselect_all"):
                        st.session_state.mart_selected_files = set()
                        st.rerun()

                # File list with checkboxes
                search_filter = st.text_input("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åã§çµã‚Šè¾¼ã¿", key="mart_file_search")
                filtered_files = files
                if search_filter:
                    filtered_files = [f for f in files if search_filter.lower() in f.lower()]

                st.caption(f"è¡¨ç¤ºä¸­: {len(filtered_files)} / {len(files)} ãƒ•ã‚¡ã‚¤ãƒ«")

                # Display files in a scrollable container
                with st.container(height=300):
                    for f in filtered_files:
                        meta = manifest.get("files", {}).get(f, {})
                        title = meta.get("source_title", f)[:60]
                        channel = meta.get("channel", "")

                        is_selected = f in st.session_state.mart_selected_files
                        col1, col2 = st.columns([0.05, 0.95])
                        with col1:
                            if st.checkbox("é¸æŠ", value=is_selected, key=f"mart_chk_{f}", label_visibility="collapsed"):
                                st.session_state.mart_selected_files.add(f)
                            else:
                                st.session_state.mart_selected_files.discard(f)
                        with col2:
                            st.markdown(f"**{title}** - _{channel}_")

                selected_count = len(st.session_state.mart_selected_files)
                st.info(f"ğŸ“Š é¸æŠä¸­: {selected_count} ãƒ•ã‚¡ã‚¤ãƒ«")

                st.divider()

                # Output settings
                st.subheader("ğŸ“¤ å‡ºåŠ›è¨­å®š")
                output_dir = st.text_input(
                    "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
                    value=f"data/marts/{mart_type}",
                    key="mart_output_dir"
                )

                # Generate button
                st.divider()
                if st.button("ğŸš€ ãƒãƒ¼ãƒˆç”Ÿæˆ", type="primary", disabled=selected_count == 0):
                    generate_mart(
                        list(st.session_state.mart_selected_files),
                        mart_type,
                        warehouse_dir,
                        output_dir
                    )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    # Tab 6: Log
    with tab6:
        st.header("åé›†ãƒ­ã‚°")

        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("ğŸ—‘ï¸ ãƒ­ã‚°ã‚¯ãƒªã‚¢"):
                clear_log()
                st.rerun()

        if st.session_state.collection_log:
            log_text = "\n".join(st.session_state.collection_log)
            st.code(log_text, language=None)
        else:
            st.info("ãƒ­ã‚°ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“")


def collect_single(source_type, source_value, max_videos, warehouse_dir, json_path):
    """Collect from a single source."""
    clear_log()
    log_message(f"åé›†é–‹å§‹: {source_type}")

    settings = Settings(quiet_mode=True)
    collector = YouTubeCollector(settings, status_callback=log_message)

    progress = st.progress(0)
    status = st.empty()

    try:
        status.info("ğŸ”„ å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")
        log_message("å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")

        videos = []
        if source_type == "å‹•ç”»URL":
            urls = [u.strip() for u in source_value.strip().split('\n') if u.strip()]
            videos = collector.collect_from_urls(urls, max_videos=max_videos, verbose=False)
        elif source_type == "ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ":
            videos = collector.collect_from_playlist(source_value, max_videos=max_videos, verbose=False)
        elif source_type == "ãƒãƒ£ãƒ³ãƒãƒ«":
            videos = collector.collect_from_channel(source_value, max_videos=max_videos, verbose=False)
        else:
            videos = collector.collect_from_search(source_value, max_videos=max_videos, verbose=False)

        progress.progress(50)
        log_message(f"å–å¾—å®Œäº†: {len(videos)} å‹•ç”»")

        if videos:
            # Save to warehouse
            if warehouse_dir:
                status.info("ğŸ’¾ Warehouseã«ä¿å­˜ä¸­...")
                log_message("Warehouseã«ä¿å­˜ä¸­...")
                result = collector.save_warehouse(videos, warehouse_dir=warehouse_dir)
                saved = result['saved']
                skipped = result.get('skipped', 0)
                if skipped > 0:
                    log_message(f"Warehouseä¿å­˜: {saved} ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{skipped} ä»¶ã¯æ—¢å­˜ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                else:
                    log_message(f"Warehouseä¿å­˜: {saved} ãƒ•ã‚¡ã‚¤ãƒ«")

            # Save to JSON
            if json_path:
                log_message("JSONã«ä¿å­˜ä¸­...")
                collector.save_json(videos, output_path=json_path)
                log_message(f"JSONä¿å­˜: {json_path}")

            progress.progress(100)
            status.success(f"âœ… å®Œäº†: {len(videos)} å‹•ç”»ã‚’åé›†ã—ã¾ã—ãŸ")
            log_message("åé›†å®Œäº†!")

            # Show results
            st.subheader("åé›†çµæœ")
            for v in videos[:10]:
                st.write(f"- **{v.metadata.title}** ({v.metadata.channel})")
            if len(videos) > 10:
                st.write(f"... ä»– {len(videos) - 10} ä»¶")

        else:
            status.warning("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            log_message("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_keywords(keywords, max_videos, warehouse_dir):
    """Batch collect from keywords."""
    clear_log()
    log_message(f"ãƒãƒƒãƒåé›†é–‹å§‹: {len(keywords)} ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")

    from insight_youtube_collector.batch import BatchConfig, SourceConfig, BatchCollector

    # Build config
    sources = [SourceConfig("keyword", kw, max_videos) for kw in keywords]
    config = BatchConfig(
        sources=sources,
        save_warehouse=bool(warehouse_dir),
        warehouse_dir=warehouse_dir or "data/warehouse/lectures",
        save_json=False,
    )

    progress = st.progress(0)
    status = st.empty()

    try:
        total = len(keywords)
        for i, kw in enumerate(keywords):
            status.info(f"ğŸ”„ [{i+1}/{total}] æ¤œç´¢ä¸­: {kw}")
            log_message(f"æ¤œç´¢ä¸­: {kw}")
            progress.progress((i + 1) / (total + 1))

        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        # Show summary
        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])
        if result.get('save_results', {}).get('warehouse'):
            wh = result['save_results']['warehouse']
            st.metric("ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«æ•°", wh['saved'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_urls(urls, max_videos, warehouse_dir):
    """Batch collect from URLs."""
    clear_log()
    log_message(f"ãƒãƒƒãƒåé›†é–‹å§‹: {len(urls)} URL")

    from insight_youtube_collector.batch import BatchConfig, SourceConfig, BatchCollector

    # Auto-detect source types
    sources = []
    for url in urls:
        if 'playlist?list=' in url:
            sources.append(SourceConfig("playlist", url, max_videos))
        elif '/@' in url or '/channel/' in url or '/c/' in url:
            sources.append(SourceConfig("channel", url, max_videos))
        else:
            sources.append(SourceConfig("url", url, 1))

    config = BatchConfig(
        sources=sources,
        save_warehouse=bool(warehouse_dir),
        warehouse_dir=warehouse_dir or "data/warehouse/lectures",
        save_json=False,
    )

    progress = st.progress(0)
    status = st.empty()

    try:
        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


def collect_batch_config(config_file, warehouse_dir):
    """Batch collect from config file."""
    import tempfile
    import yaml
    import json

    clear_log()
    log_message("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒƒãƒåé›†é–‹å§‹")

    progress = st.progress(0)
    status = st.empty()

    try:
        # Save uploaded file temporarily
        content = config_file.read().decode('utf-8')

        if config_file.name.endswith('.json'):
            data = json.loads(content)
        else:
            import yaml
            data = yaml.safe_load(content)

        config = BatchConfig.from_dict(data)
        log_message(f"è¨­å®šèª­ã¿è¾¼ã¿: {len(config.sources)} ã‚½ãƒ¼ã‚¹")

        status.info("ğŸ”„ åé›†å®Ÿè¡Œä¸­...")
        collector = BatchCollector(config, verbose=False)
        result = collector.collect_all()

        progress.progress(100)
        log_message(f"åé›†å®Œäº†: {result['unique_videos']} å‹•ç”»")

        status.success(f"âœ… å®Œäº†: {result['unique_videos']} å‹•ç”»ã‚’åé›†")

        st.metric("åé›†å‹•ç”»æ•°", result['unique_videos'])

    except Exception as e:
        status.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        log_message(f"ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    main()
